# Заметки по теории вероятностей из курса Райгородского Андрея Михайловича на площадке Sirus
https://edu.sirius.online/#/course/2168

## Основы комбинаторики
### Размещения и сочетания
Пусть есть множество из n элементов.

- _Число размещений без повторений_ $A_{n}^{k}$ — количество способов расположить на k пронумерованных позициях элементы множества так, чтобы никакие два не повторялись.
- _Число размещений с повторениями_ $\bar{A}_{n}^{k}$ — количество способов расположить на k пронумерованных позициях элементы множества (на разных позициях элементы могут повторяться).
- _Число сочетаний без повторений_ $C_{n}^{k}$ — количество способов выбрать набор из k элементов, где элементы не повторяются.
- _Число сочетаний с повторениями_ $\bar{C}_{n}^{k}$ — количество способов выбрать набор из k элементов, где элементы могут повторяться.

Если исходное множество — это алфавит (то есть n = 33), то указанные величины соответствуют следующему:

- $A_{n}^{k}$ равно количеству слов длины k, состоящих из различных букв;
- $\bar{A}_{n}^{k}$ равно количеству слов длины k, состоящих из необязательно различных букв;
- $C_{n}^{k}$ равно количеству наборов из k различных букв (то есть наборов букв без учёта порядка);
- $\bar{C}_{n}^{k}$ равно количеству наборов из k необязательно различных букв (то есть наборов букв без учёта порядка).

### Размещения и сочетания. Формулы
Через $n!$ обозначается произведение натуральных чисел от 1 до n. Удобно считать, что $0!=1$. Тогда формулы для числа размещений и числа сочетаний можно записать в следующем виде:

- $A_{n}^{k}=\frac{n!}{(n−k)!}=n⋅(n−1)⋅…⋅(n−k+1)$;
- $\bar{A}_{n}^{k}=n^k$;
- $C_{n}^{k}=\frac{n!}{k!⋅(n−k)!}=\frac{n⋅(n−1)⋅…⋅(n−k+1)}{k}!$;
- $\bar{C}_{n}^{k}=C_{n+k−1}^{k}$ (без доказательства).

Количество _перестановок_ чисел от 1 до n (то есть количество способов записать эти числа в ряд в каком-нибудь порядке) равно $n!$.

### Бином Ньютона
**Бином Ньютона.** При натуральном n выполнено равенство

$(x+y)^n=C_{n}^{0}⋅x^n+C_{n}^{1}⋅x^{n−1}y+C_{n}^{2}⋅x^{n−2}y^2+…+C_{n}^{k}⋅x^{n−k}y^k+…+C_{n}^{n}⋅y^n$.

В честь бинома числа сочетаний $C_{n}^{k}$ также называют _биномиальными коэффициентами_.

Для доказательства заметим, что в левой части стоит произведение n скобок. Слагаемое $x^{n−k}y^k$ получается, если выбрать y из k скобок и x из оставшихся n−k скобок. Количество способов сделать это как раз равно $C_{n}^{k}$.

### Свойства биномиальных коэффициентов
**Свойства биномиальных коэффициентов**

- $C_{n}^{k}=C_{n}^{n-k}$. Это свойство можно легко увидеть из явной формулы, однако оно легко следует и из комбинаторных соображений: выбрать k объектов из n — это то же самое, что не выбрать n−k объектов из n.
- $C_{n}^{k}=C_{n-1}^{k}+C_{n-1}^{k-1}$. Это свойство также можно доказать как алгебраически, так и комбинаторно. Рассмотрим множество из n элементов и выделим в нём один элемент. Тогда все способы выбрать k элементов из n можно разбить на две части: выделенный элемент не выбран или выбран. В первом случае количество вариантов равно $C_{n-1}^{k}$, а во втором — $C_{n-1}^{k-1}$.
- $C_{n}^{0}+C_{n}^{1}+…+C_{n}^{n}=2^n$. Алгебраически это тождество следует из бинома, в который подставили единицы:
    
    $C_{n}^{0}+C_{n}^{1}+…+C_{n}^{n}=(1+1)^n=2^n$.
    
    Комбинаторно это тождество следует из того, что и левая, и правая части равны количеству последовательностей из n цифр, каждая из которых равна 0 или 1.

## Классическое определение вероятности
### Пример с игральным кубиком
Рассмотрим подбрасывание идеального игрального кубика. Обозначим возможные результаты через $\omega_{1},\omega_{2},...,\omega_{6}$, где $\omega_{1}$ соответствует выпаданию единицы, $\omega_{2}$ — выпаданию двойки и так далее.

Мы считаем, что:

- $\omega_{1},\omega_{2},...,\omega_{6}$ исчерпывают все возможные исходы;
- никакие два исхода из $\omega_{1},\omega_{2},...,\omega_{6}$ не могут произойти одновременно;
- исходы $\omega_{1},\omega_{2},...,\omega_{6}$ равновероятны.

В таких предположениях естественно задать вероятности каждого из исходов как $P(\omega_{i})=\frac{1}{6}$ для $i$ от 1 до 6.

### Определение
Рассмотрим эксперимент, в результате которого могут реализоваться конечное число n _элементарных исходов_ (_элементарных событий_) $\omega_{1},\omega_{2},...,\omega_{n}$ таких, что

- $\omega_{1},\omega_{2},...,\omega_{n}$ исчерпывают все возможные результаты эксперимента;
- никакие два исхода из $\omega_{1},\omega_{2},...,\omega_{n}$ не могут произойти одновременно;
- исходы $\omega_{1},\omega_{2},...,\omega_{n}$ равновероятны.

Тогда естественно задать вероятность каждого из исходов как $P(\omega_{i})=\frac{1}{n}$.

_Пример._ Рассмотрим результат перетасовки колоды из 36 игральных карт. Элементарными исходами будут все возможные порядки карт в колоде. Всего 36 карт можно расположить 36! способами, а значит, вероятность любого отдельного порядка карт в колоде $P(\omega_{i})=\frac{1}{36!}$.

### Событие и его вероятность
_Событие_ — это некоторое множество элементарных исходов. Событие, не содержащее ни одного элементарного исхода (то есть пустое множество, $\emptyset$), называется _невозможным событием_. Событие, состоящее из всех элементарных исходов, называется _достоверным событием_.

При классическом задании вероятностей (то есть при выполнении трёх условий, описанных в предыдущей лекции) для произвольного события A его вероятность $P(A)$. естественно задать как $P(A)=\frac{|A|}{n}$., где $|A|$ — количество элементов в множестве A.

В частности, $P(\emptyset)=0$ и $P(\{\omega_{1},\omega_{2},...,\omega_{n}\})=1$.

### Свойства вероятности
Если у эксперимента есть n элементарных исходов, то количество соответствующих ему событий равно $2^n$.

Поскольку события — это множества, то с ними можно выполнять теоретико-множественные операции.

- _Объединение_ $A \cup B$ событий A и B — это событие, отвечающее тому, что произошло событие A или событие B (не исключая того, что могли произойти оба). Иначе говоря, реализовался элементарный исход, благоприятствующий либо только A, либо только B, либо и A, и B.
- _Пересечение_ $A \cap B$ событий A и B — это событие, отвечающее тому, что произошло и событие A, и событие B. Иначе говоря, реализовался элементарный исход, благоприятствующий и A, и B.
- _Отрицание_ $\bar{A}$ события A — это событие, отвечающее тому, что событие A не произошло, то есть не реализовался ни один из элементарных исходов, благоприятствующих A. На языке теории множеств это можно записать как $\bar{A}=\{\omega_{1},\omega_{2},...,\omega_{n}\}$ \ $A$.

Достоверное событие, состоящее из всех элементарных исходов, обозначается $\Omega=\{\omega_{1},\omega_{2},...,\omega_{n}\}$

**Свойства вероятности при классическом определении**

- $P(\emptyset)=0, P(\Omega)=1$.
- Если $A \notin \{\emptyset, \Omega\}$, то $P(A) \in (0, 1)$.
- $P(A)=1 - P(\bar{A})$.
- $P(A \cup B)=P(A)+P(B)-P(A \cap B)$.

## Условная вероятность и независимость событий
### Условная вероятность
Допустим, есть пространство элементарных исходов $\Omega=\{\omega_{1},\omega_{2},...,\omega_{n}\}$ и некоторое непустое событие $B ⊆ \Omega$ (то есть $P(B)>0$), про которое известно, что оно произошло. Зададимся вопросом, чему в этом случае равна вероятность некоторого события A.

_Условной вероятностью A при условии_ B называется вероятность того, что событие A произойдёт, если известно, что событие B произошло. Условная вероятность определяется формулой
$$P(A|B)=\frac{|A \cap B|}{|B|}=\frac{P(A \cap B)}{P(B)}$$
Из этого определения непосредственно следует _теорема умножения:_
$$P(A \cap B)=P(A|B)⋅P(B)$$
### Независимость двух событий
События A и B называются _независимыми_, если $P(A \cap B)=P(A)⋅P(B)$. При этом допускается, что вероятность A или B может быть нулевой.

Когда одно из событий, например B, имеет положительную вероятность, условие независимости эквивалентно более интуитивному условию $P(A|B)=P(A)$, которое показывает, что если A не зависит от B, то реализация B не меняет вероятности A.

События A и B называются _несовместными_, если $A \cap B=\emptyset$. Важно отметить, что независимость и несовместность — это разные понятия. В частности, если два события несовместны и имеют ненулевые вероятности, то они обязательно будут зависимыми.

### Независимость нескольких событий
События $A_{1},...,A_{k}$  называются _независимыми_ (как ещё часто говорят, _независимы в совокупности_, или _взаимно независимы_), если для любого набора из этих событий верно, что вероятность пересечения всех событий в наборе равна произведению вероятностей событий в наборе.

Если говорить более формально, то $A_{1},...,A_{k}$ независимы, если для любого набора несовпадающих индексов $1⩽i_{1},…,i_{m}⩽k$ верно равенство
$$P(A_{i_{1}} \cap ... \cap A_{i_{m}})=P(A_{i_{1}})⋅…⋅P(A_{i_{m}})$$
### Пример
Если события попарно независимы, то из этого не следует, что они независимы в совокупности. Традиционный пример событий, независимых попарно, но не в совокупности, строится с помощью кубика в виде тетраэдра. Пусть три грани тетраэдра покрашены в красный, жёлтый и зёленый цвета, а на оставшейся грани есть все три цвета: и красный, и жёлтый, и зёленый. Рассмотрим три события: на выпавшей (нижней) грани тетраэдра есть красный, жёлтый и зелёный цвета. Эти три события не будут независимы, но при этом любые два из них независимы.

## Формула полной вероятности и формула Байеса
### Формула полной вероятности
**Формула полной вероятности.** Пусть множество элементарных исходов Ω разбито на непересекающиеся подмножества $B_{1},...,B_{m}$ такие, что все они имеют ненулевую вероятность. Тогда для произвольного события A его вероятность может быть вычислена по формуле
$$P(A)=P(A|B_{1})⋅P(B_{1})+...+P(A|B_{m})⋅P(B_{m})$$
Иногда под этой формулой понимают более простое аналогичное утверждение
$$P(A)=P(A \cap B_{1})+...+P(A \cap B_{m})$$
### Формула полной вероятности. Пример
_Пример._ Даны две урны. В первой находятся 3 белых и 2 чёрных шара, а во второй — 2 белых и 2 чёрных. Из первой урны наугад достаётся шар и кладётся внутрь второй урны. После этого шары во второй урне тщательно перемешивают и наугад достают из неё 2 шара. Найдите вероятность того, что оба этих шара белые.

### Формула Байеса
**Формула Байеса.** Пусть множество элементарных исходов $\Omega$ разбито на подмножества $B_{1},...,B_{m}$  такие, что они все они имеют ненулевую вероятность. Тогда для произвольного события A, имеющего ненулевую вероятность, вероятность $B_{i}$ при условии A может быть вычислена по формуле
$$P(B_{i}|A)=\frac{P(A|B_{i})⋅P(B_{i})}{P(A)}=\frac{P(A|B_{i})⋅P(B_{i})}{P(A|B_{1})⋅P(B_{1})+...+P(A|B_{m})⋅P(B_{m})}$$

### Вывод формулы Байеса через определение условной вероятности
Напомним, что $P(A|B)=\frac{|A \cap B|}{|B|}=\frac{P(A \cap B)}{P(B)}$. Откуда следует, что $P(A \cap B)=P(A|B)⋅P(B)$.
Заметим, что $P(A \cap B)=P(B \cap A)=P(B|A)⋅P(A)$. Отсюда следует следующее тождество:
$$P(A \cap B)=P(B \cap A)$$
$$P(A|B)⋅P(B)=P(B|A)⋅P(A)$$
$$P(B|A)=\frac{P(A|B)⋅P(B)}{P(A)}$$
где $P(A)$ можно посчитать по формуле полной вероятности.
### Формула Байеса. Пример
_Пример._ Студент решает задачу с $k$ вариантами ответа. Если студент знает, как решать задачу, он даёт правильный ответ. Если нет — может угадать его с вероятностью $\frac{1}{k}$. Профессор знает, что вероятность того, что студент знает, как решать задачу, равна $p$. Студент дал правильный ответ. Найдите вероятность того, что студент дал правильный ответ, зная решение задачи, а не угадав его.

## Схема испытаний Бернулли
### Элементарные исходы
Схема испытаний Бернулли описывает последовательность $n$ независимых испытаний, каждое из которых может заканчиваться успехом или неудачей. Типичный пример — последовательность из $n$ подбрасываний несимметричной монеты, где выпадание решки можно условно считать успехом, а выпадание орла — неудачей.

Вероятность успеха в одном испытании традиционно обозначается $p$, а вероятность неудачи часто обозначается $q=1−p$.

Элементарным исходом в данной схеме является последовательность из $n$ нулей и единиц. Если на i-й позиции в этой последовательности стоит 1, то в i-м испытании результатом был успех, если стоит 0, то результатом была неудача.

### Вероятность элементарного исхода
Всего в схеме испытаний Бернулли возможно $2^n$  различных элементарных исходов. Вероятность элементарного исхода $\omega=(x_{1},x_{2},...,x_{n})$ в схеме испытаний Бернулли естественно задать как
$$P(\omega)=p^{\Sigma_{i=1}^{n}x_{i}}⋅q^{n-\Sigma_{i=1}^{n}x_{i}}$$
где $\Sigma_{i=1}^{n}x_{i}$ и $n-\Sigma_{i=1}^{n}x_{i}$ задают количество успехов и неудач соответственно в случае реализации данного элементарного исхода.

Такое задание является естественным следствием предположения о независимости испытаний, поскольку при независимости испытания вероятности результатов каждого из испытаний следует перемножить, и каждый успех вносит $p$ в произведение, а каждая неудача — $q=1−p$.

В случае $p=q=\frac{1}{2}$ такая схема вырождается в частный случай классического определения вероятности, поскольку вероятности всех исходов становятся одинаковы и равны $\frac{1}{2^n}$.
### Вероятность события и свойства
Для каждого события $A⊆\Omega=\{\omega_{1},...,\omega_{m}\}$ вероятность этого события естественно задать как сумму вероятностей входящих в него элементарных исходов: $P(A)=\Sigma_{\omega \in A} P(\omega)$.

Заданная таким образом вероятность удовлетворяет свойствам, уже знакомым по случаю классической вероятности:

- $P(\emptyset)=0$, $P(\Omega)=1$, и если $A \notin \{\emptyset,\Omega\}$, то $P(A)∈(0,1)$;
- $P(A)=1−P(\bar{A})$;
- $P(A \cup B)=P(A)+P(B)−P(A \cap B)$.

### Пример решения задачи
_Задача._ Из множества $\{1,2,...,n\}$ выбираются два подмножества A и B следующим образом: каждый элемент выбирается в подмножество A с вероятностью $p$, аналогично строится подмножество B. Найдите вероятность того, что множества A и B не пересекаются.

## Случайные графы
### Что такое граф
Формально _графом_ называется упорядоченная пара $(V, E)$, где $V$ — множество вершин, а $E$ — множество рёбер, то есть пар вершин. Графически вершины графа обозначаются точками, а рёбра — соединяющими их линиями. Пары вершин могут быть неупорядоченными или упорядоченными. В последнем случае они также называются _ориентированными_ рёбрами, а соответствущий граф — _ориентированным_ графом.

Рёбра, соединяющие вершину с самой собой _(петли)_, или несколько рёбер, соединяющих одни и те же вершины _(кратные рёбра)_, могут быть разрешены или запрещены в зависимости от конкретных задач. По умолчанию мы рассматриваем _простые_ графы, то есть графы, в которых нет ориентированных рёбер, петель или кратных рёбер.
![[Кратные ребра и петля.png]]

### Что такое случайный граф
Приведём модель случайного графа. Рассмотрим $K_{n}$ — полный граф с $n$ вершинами, то есть граф с $n$ вершинами, в котором присутствуют все $C_{n}^{2}=\frac{n(n−1)}{2}$ возможных рёбер. Каждое из рёбер независимо сохраняется с вероятностью $p$ (или исчезает с вероятностью $q=1−p$). Это соответствует схеме испытаний Бернулли, где сохранения или исчезновения каждого из $C_{n}^{2}$ рёбер являются испытаниями, и успехом считается сохранение ребра, происходящее с вероятностью $p$.

Занумеруем рёбра. Тогда элементарные исходы в получившейся схеме испытаний Бернулли имеют вид последовательностей из $C_{n}^{2}$ нулей и единиц, где ребро под номером $i$ проведено тогда и только тогда, когда на $i$-м месте в последовательности стоит единица.

Модель случайного графа имеет практические приложения. Например, задача об устойчивости сети, в которой каждый сервер соединён с подобным ему, и часть из связей между ними разрушается независимо друг от друга с вероятностью $1−p$. Типичный вопрос: останется ли сеть связной? То есть можно ли будет в уцелевшей части сети построить маршрут между любыми двумя серверами?

### События
Событием в модели случайного графа с $n$ вершинами будет множество $A$, состоящее из графов с $n$ вершинами. Часто в качестве таких множеств берут набор всех графов, обладающих некоторым свойством. Например, набор связных графов, то есть тех, в которых существует маршрут между любыми двумя вершинами, или графов, содержащих треугольник.


## Случайные величины
### Конечное вероятностное пространство
_Конечным вероятностным пространством_ называется конечное множество элементарных исходов $\Omega=\{\omega_1,...,\omega_n\}$, каждому из которых приписано некоторое число $P(\omega_i)=p_i \in (0,1)$, причём сумма этих чисел равна единице:
$$p_1+p_2+...+p_n=1$$
Событие — это любое подмножество пространства элементарных исходов $A⊆ \Omega$, вероятность события задаётся суммой вероятностей принадлежащих ему элементарных исходов:
$$P(A)=\Sigma_{\omega \in A} P(\omega)$$
Классический способ задания вероятностей и схема испытаний Бернулли являются частными случаями этой модели.

Стандартные свойства вероятности выполняются и в этой модели:

- $P(\emptyset)=0, P(\Omega)=1$, и если $A \notin \{\emptyset,\Omega\}$, то $P(A)∈(0,1)$;
- $P(A)=1−P(\bar{A})$;
- $P(A∪B)=P(A)+P(B)−P(A∩B)$.

### Случайная величина
_Случайная величина_ — это функция, аргументом которой выступают элементарные исходы. Её значениями при подстановке конкретных элементарных исходов будут какие-то действительные числа.

Для любой случайной величины $X$ и некоторого значения y, которое она принимает, можно рассмотреть событие $X=y$. Это событие включает все исходы такие, что X принимает на них значение y, то есть его можно записать в виде $\{ω∈\Omega:X(\omega)=y\}$. Тогда вероятность этого события можно найти как сумму вероятностей всех таких исходов, то есть
$$P(X=y)=∑_{ω:X(ω)=y}P(ω)$$
Можно рассмотреть все значения, которые принимает $X: y_1,…,y_k$, где $k$ — натуральное число, не превосходящее $n$. Тогда события $X=y_i$ будут попарно непересекающимися и в совокупности покроют всё пространство. Поэтому в силу свойств вероятности
$$P(X=y_1)+P(X=y_2)+…+P(X=y_k)=1$$
Набор вероятностей всех этих событий называется _распределением_ случайной величины $X$.

### Распределение случайной величины

Рассмотрим схему испытаний Бернулли c вероятностью успеха $p$ и $n$ испытаниями. Определим случайную величину $μ_n(ω)$ как количество успехов в элементарном исходе $ω$, то есть её можно задать формулой
$$μ_n(ω)=∑_{i=1}^{n}x_i,$$
где $ω=(x_1,…,x_n)$ — элементарный исход, представленный в виде последовательности нулей и единиц. Эта случайная величина принимает значения от 0 до n, и вероятность того, что она примет значение k, равно
$$P(μ_n=k)=C_{n}^{k}p^k(1−p)^{n−k}.$$
Говорят, что величина $μ_n$ имеет _биномиальное распределение_.

Такое распределение случайной величины может возникать не только в таком контексте, но и, например, как количество рёбер в случайном графе, и во многих других ситуациях. Будем говорить, что случайная величина X на произвольном пространстве элементарных исходов имеет биномиальное распределение, если она принимает значения от 0 до n с вероятностями
$$P(X=k)=C_{n}^{k}p^{k}(1−p)^{n−k}$$
для некоторого $p∈(0,1)$. Такое распределение обозначают $Binom(n,p)$.

В более общем случае распределение случайных величин может быть весьма нетривиальным. Например, число треугольников в случайном графе на $n$ вершинах является случайной величиной, принимающей значения от 0 до $C_n^3$, распределение которой найти далеко не просто.

### Независимость двух случайных величин

Пусть случайная величина $X$ принимает значения $y_1,…,y_k,$ а случайная величина $Y$ — значения $z_1,…,z_m$. Эти случайные величины называются _независимыми_, если для любого $1⩽i⩽k$ и любого $1⩽j⩽m$ события $X=y_i$ и $Y=z_j$ независимы, то есть

$$P(X=y_i,Y=z_j)=P(X=y_i)⋅P(Y=z_j).$$

### Независимость нескольких случайных величин

Набор $X_1,…,X_s$ случайных величин называется _независимым в совокупности_, если для любого $t⩽s$ и для любых номеров $1⩽i_1<…<i_t⩽s$, а также для любого набора из t чисел a,b,…,c верно равенство

$$P(X_{i_1}=a,X_{i_2}=b,…,X_{i_t}=c)=P(X_{i_1}=a)⋅P(X_{i_2}=b)⋅…⋅P(X_{i_t}=c).$$

Для произвольного события $A$ его _индикатором_ $I_A(ω)$ называется случайная величина, которая равна 1, если $ω∈A$, и равна 0, если иначе. Используя эти случайные величины и пример трёх попарно независимых событий, зависимых в совокупности, можно построить пример трёх случайных величин, независимых попарно, но не являющихся независимыми в совокупности.


## Математическое ожидание
### Определение
Пусть случайная величина $X$ определена на конечном вероятностном пространстве с элементарными исходами $ω_1,…,ω_n$ и их вероятностями $p_1,…,p_n$ соответственно. _Математическое ожидание (матожидание)_ величины $X$ — это характеристика, имеющая смысл среднего значения величины, и она задаётся формулой

$$EX=∑_{i=1}^{n}X(ω_i)⋅p_i.$$

(Вместо $EX$ в некоторых источниках используют обозначение $MX$.)

Математическое ожидание также может быть выражено в терминах распределения $X$, а именно, если $X$ принимает значения $y_1,…,y_k$, то

$$EX=∑_{i=1}^{k}y_i⋅P(X=y_i).$$
### Линейность математического ожидания
Пусть $X$ и $Y$ — случайные величины, определённые на одном вероятностном пространстве $\Omega$. _Суммой_ $X+Y$ назовём случайную величину, которая на элементарном исходе $ω∈Ω$ принимает значение $X(ω)+Y(ω)$, то есть

$$(X+Y)(ω)=X(ω)+Y(ω).$$

Математическое ожидание имеет следующие свойства:

- $E(c⋅X)=c⋅EX$, где $X$ — случайная величина, а $c∈R$ — некоторое число;
- $E(X+Y)=EX+EY$, где $X$ и $Y$ — случайные величины, определённые на одном вероятностном пространстве (в том числе, возможно, зависимые).

Вместе эти два свойства позволяют утверждать, что для произвольных случайных величин $X$ и $Y$, определённых на одном вероятностном пространстве, и чисел $c_1$ и $c_2$ выполнено равенство
$$E(c_1⋅X+c_2⋅Y)=c_1⋅EX+c_2⋅EY.$$
Это свойство называется _линейностью_ математического ожидания.
### Математическое ожидание произведения
Пусть $X$ и $Y$ — случайные величины, определённые на одном вероятностном пространстве $Ω$. _Произведением_ $XY$ назовём случайную величину, которая на элементарном исходе $ω∈Ω$ принимает значение $X(ω)⋅Y(ω)$, то есть
$$XY(ω)=X(ω)⋅Y(ω).$$
Если величины $X$ и $Y$ независимы, то
$$E(XY)=EX⋅EY.$$
Для случайных величин, которые не являются независимыми, это утверждение может быть неверно.

### Пример вычисления математического ожидания
Пусть случайная величина $X$ имеет распределение $Binom(n,p)$. Тогда $EX=np$. Это легко доказать, если представить $X$ в виде
$$X=X_1+X_2+…+X_n,$$
где $X_i$ — случайная величина, равная 1, если в $i$-м испытании произошёл успех, и 0 в противном случае.

### Математическое ожидание числа треугольников
Пусть в случайном графе с $n$ вершинами вероятность проведения ребра равна $p$. Через $X$ обозначим случайную величину, равную количеству треугольников.

Найти распределение $X$ очень сложно, но $EX$ несложно посчитать, если воспользоваться линейностью математического ожидания. Для этого занумеруем все возможные тройки вершин числами от 1 до $C_n^3$. Представим $X$ в виде суммы случайных величин $X_1,…,X_{C_n^3}$, где $X_i$ равна 1, если $i$-я тройка образует треугольник, и 0, если иначе. Тогда, пользуясь линейностью, несложно показать, что $EX=C_n^3⋅p^3$.

## Дисперсия
### Определение
_Дисперсией_ $DX$ случайной величины X называется математическое ожидание квадрата отклонения случайной величины от её математического ожидания:
$$DX=E((X−EX)^2).$$
Дисперсию часто удобнее считать, используя эквивалентную формулу
$$DX=E(X^2)−(EX)^2.$$
$E(X^2)$ часто называют _вторым моментом_ случайной величины $X$.

### Свойства дисперсии
**Свойства дисперсии**
- Для случайной величины $X$ и $c∈R$ выполнено равенство $D(c⋅X)=c^2⋅DX$.
- Если случайные величины $X$ и $Y$ независимы, то $D(X+Y)=DX+DY$.

### Ковариация и коэффициент корреляции
_Ковариацией_ двух случайных величин $X$ и $Y$ называется величина
$$cov(X,Y)=E(XY)−(EX)⋅(EY).$$
В частности, $cov(X,X)=D(X)$. Если $cov(X,Y)=0$, то величины $X$ и $Y$ называют _некоррелированными_.

_Коэффициентом корреляции_ $ρ(X,Y)$ случайных величин $X$ и $Y$ называется значение выражения
$$ρ(X,Y)=\frac{cov(X,Y)}{\sqrt{DX⋅DY}}.$$
Если случайные величины $X$ и $Y$ независимы, то они являются некоррелированными. Обратное неверно — например, две случайные величины, определённые следующим образом на $Ω=\{1,2,3,4\}$ с равными вероятностями каждого исхода

| $\omega$ | 1   | 2   | 3   | 4   |
| -------- | --- | --- | --- | --- |
| $X$      | 0   | 1   | 0   | -1  |
| $Y$      | 1   | 0   | -1  | 0   |
зависимые, но некоррелированные.


## Геометрическая вероятность
### Определение
_Задача._ Коля и Вася договорились встретиться на остановке между 9:00 и 10:00. Каждый из них независимо от другого приходит в случайный момент времени в указанном интервале и ждёт прихода другого 15 минут (но не после 10:00). С какой вероятностью Коля и Вася встретятся?

Эту задачу можно свести к случаю классической вероятности, разбив время на конечные интервалы и выбрав точки в соответствующих интервалах времени. Такое решение не вполне приемлемо, поскольку непонятно, какую именно длину интервала выбирать, чем одна длина интервала лучше любой другой. Естественно будет рассмотреть предельный случай, когда вместо рассмотрения отдельных точек рассматриваются непрерывные геометрические фигуры, и вероятность попасть в фигуру считается пропорциональной площади этой фигуры.

Изобразим время прихода Коли и Васи точками на координатной плоскости. Подходящее время прихода закрашено на рисунке серым.
![[001_400.png]]
Отношение закрашенной части к площади всего квадрата равна $\frac{7}{16}$ — это число и логично назвать вероятностью встречи.

Формально в качестве пространства элементарных исходов рассматривается квадрат $Ω=[0,1]^2$, события — это подмножества $A⊆Ω$, вероятность события $A$ задаётся как
$$P(A)=\frac{Площадь A}{Площадь Ω}.$$
Вообще говоря, невозможно разумно приписать площадь всем подмножествам Ω. Обычно на практике такие множества не возникают, однако это нужно иметь в виду при формализации.

В общем случае в качестве $Ω$ можно взять любое множество на плоскости (на прямой или в трёхмерном пространстве), для которого площадь (или длина, или объём) могут быть определены и являются конечными. В качестве событий взять все его подмножества $A$, для которых площадь (длина или объём) также может быть определена, их вероятность тогда задаётся как отношение их площади (длины или объёма) к площади (длине или объёму) всего $Ω$.

### Свойства
Некоторые свойства геометрической вероятности похожи на свойства вероятности в случае конечного вероятностного пространства.
- $P(A)∈[0,1]$ для любого события $A$, $P(∅)=0, P(Ω)=1$.
- $P(A)=1−P(\bar{A})$.
- $P(A∪B)=P(A)+P(B)−P(A∩B).$
Принципиальное отличие заключается в том, что в случае геометрической вероятности бывают непустые события, вероятность которых равна 0 (и, соответственно, их дополнения, не равные всему пространству, но вероятность которых равна 1). Примерами событий вероятности 0 могут быть отдельные точки на прямой или на плоскости, линии на плоскости.

### Парадокс Бертрана
_Задача._ Рассмотрим случайную хорду окружности. С какой вероятностью длина этой хорды будет больше длины стороны равностороннего треугольника, вписанного в эту окружность?

В зависимости от того, что понимать под «случайной хордой», ответ на эту задачу будет разным.

_Первый способ._ Зафиксируем один конец хорды $A$, а другой будем выбирать случайно. Тогда хорда будет длиннее стороны равностороннего треугольника, когда второй конец будет лежать на оранжевой дуге.
![[007_400.png]]
Таким образом, при фиксированной точке $A$ вероятность благоприятного исхода равна $\frac{1}{3}$, так как оранжевая дуга составляет треть окружности. Для любой другой точки получится та же вероятность, поэтому и итоговая вероятность равна $\frac{1}{3}$.

_Второй способ._ Будем считать, что середина хорды — это случайно выбранная точка. Вероятностное пространство — это круг, ограниченный окружностью. Несложно видеть, что если точка не совпадает с центром окружности, то существует единственная хорда, серединой которой является эта точка. Так как радиус вписанной в равносторонний треугольник окружности в два раза меньше радиуса описанной окружности, то подходят хорды, у которых середина лежит внутри вдвое меньшего концентрического круга.
![[008.1_400.png]]
Таким образом, искомая вероятность равна отношению площадей кругов, то есть $\frac{1}{4}$.

То, что получаются разные вероятности, на самом деле не является парадоксом. При разных заданиях вероятностного пространства может получаться разная вероятность.

### Аксиоматика Колмогорова
Дадим общее определение вероятностного пространства. Вероятностное пространство — это набор из трёх объектов, $(Ω,F,P)$.

$Ω$ — это любое множество, которое называется _пространством элементарных исходов_.
$F$ — это совокупность подмножеств Ω, обладающая следующими свойствами:
- $∅,Ω∈F$;
- $A,B∈F⟹\bar{A},A∩B,A∪B∈F$;
- $A_1,…,A_n,…∈F⟹⋃_{i=1}^{∞}A_i,⋂_{i=1}^{∞}A_i∈F$.

Систему подмножеств, удовлетворяющих этим свойствам, называют σ-_алгеброй_.
$P$ — это функция из $F$ в отрезок $[0,1]$, удовлетворяющая следующим свойствам:
- $P(∅)=0, P(Ω)=1$;
- $P(A)=1−P(\bar{A})$;
- для любых $A,B∈F$ таких, что $A∩B=∅$, выполнено равенство $P(A∪B)=P(A)+P(B)$;
- для любых $A_1,…,A_n,…∈F$ таких, что $A_i∩A_j=∅$ для всех $i$ и $j$, выполнено равенство
$$P(⋃_{i=1}^{∞}A_i)=∑_{i=1}^{∞}P(A_i).$$
